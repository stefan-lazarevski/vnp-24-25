{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Install the required packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed install the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasetsNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.12.4-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (2.0.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-18.1.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (4.66.5)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from datasets)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\miniconda3\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\miniconda3\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Downloading transformers-4.47.1-py3-none-any.whl (10.1 MB)\n",
      "   ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/10.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.6/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.1/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.9/10.1 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.9/10.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.7/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.5/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 6.3/10.1 MB 3.7 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.1/10.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.7/10.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.7/10.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.1/10.1 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading imbalanced_learn-0.12.4-py3-none-any.whl (258 kB)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.11-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading huggingface_hub-0.27.0-py3-none-any.whl (450 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-18.1.0-cp312-cp312-win_amd64.whl (25.1 MB)\n",
      "   ---------------------------------------- 0.0/25.1 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.8/25.1 MB 3.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 1.6/25.1 MB 3.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 2.4/25.1 MB 3.6 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 3.1/25.1 MB 3.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/25.1 MB 3.7 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.7/25.1 MB 3.7 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.5/25.1 MB 3.7 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.3/25.1 MB 3.7 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.1/25.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.9/25.1 MB 3.7 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.7/25.1 MB 3.6 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.4/25.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/25.1 MB 3.6 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.7/25.1 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.5/25.1 MB 3.6 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.3/25.1 MB 3.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 13.1/25.1 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.9/25.1 MB 3.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 14.7/25.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.5/25.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 16.3/25.1 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 17.3/25.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 17.8/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.6/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 19.4/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.2/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 21.0/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 21.5/25.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 22.3/25.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.8/25.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.6/25.1 MB 3.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 24.4/25.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.9/25.1 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.1/25.1 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Downloading safetensors-0.4.5-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.8/2.4 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Installing collected packages: xxhash, safetensors, regex, pyarrow, propcache, multidict, fsspec, frozenlist, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, imbalanced-learn, aiohttp, transformers, datasets, evaluate\n",
      "Successfully installed aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.27.0 imbalanced-learn-0.12.4 multidict-6.1.0 multiprocess-0.70.16 propcache-0.2.1 pyarrow-18.1.0 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.1 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    }
   ],
   "source": [
    "pip install datasets transformers imbalanced-learn evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Laboratory Exercise - Run Mode (8 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This laboratory assignment's primary objective is to fine-tune a pre-trained language model for detection of toxic sentences (binary classification). \n",
    "\n",
    "The dataset contains two attributes: \n",
    "- `text`: The sentence which needs to be classified in to toxic/non-toxic\n",
    "- `label`: 0/1 indicator if the given sentence is toxic\n",
    "\n",
    "**Note: You are required to perform this laboratory assignment on your local machine.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data\n",
    "\n",
    "The dataset reading is given. Just run the following 2 cells.\n",
    "\n",
    "**DO NOT MODIFY IT! Just analyse how the data reading was performed, as in the future this part won't be given.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1676cd76b44c4d70a295bf221c11e6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511d46341c3c474493c527935b6220de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating val split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df89b0a613884663af94e7403043f897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    'csv', \n",
    "    data_files={'train': 'data/train.tsv', 'val': 'data/val.tsv','test': 'data/test.tsv'},\n",
    "    delimiter='\\t'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The prediction target column MUST be named 'label' in the dataset !**\n",
    "\n",
    "See the dataset structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3130\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3132\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Tokenizer and Data Collator\n",
    "\n",
    "For the purposes of this lab you will be using `DistilBertTokenizer` and `DataCollatorWithPadding`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b48c114707a141ca8afb392839a8431e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub\\models--distilbert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8dbafa017fd4d51982e9c05f841c0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02436849ea46416fa523d0320904ce29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8911ba913a40471c9e24c51ba285b6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import DistilBertTokenizer, DataCollatorWithPadding\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the dataset\n",
    "\n",
    "For the purposes of lowering the amount of computing set the `max_length` parameter to 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    lambda examples: tokenizer(\n",
    "        examples[\"text\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=15\n",
    "    ), \n",
    "    batched=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "\n",
    "The required model for this lab is the `DistilBertForSequenceClassification`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl.metadata (6.2 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\miniconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\miniconda3\\lib\\site-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.5.1-cp312-cp312-win_amd64.whl (203.0 MB)\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/203.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/203.0 MB 840.2 kB/s eta 0:04:02\n",
      "   ---------------------------------------- 0.8/203.0 MB 1.1 MB/s eta 0:03:07\n",
      "   ---------------------------------------- 1.6/203.0 MB 1.8 MB/s eta 0:01:51\n",
      "   ---------------------------------------- 2.4/203.0 MB 2.2 MB/s eta 0:01:30\n",
      "    --------------------------------------- 3.1/203.0 MB 2.5 MB/s eta 0:01:20\n",
      "    --------------------------------------- 3.9/203.0 MB 2.7 MB/s eta 0:01:13\n",
      "    --------------------------------------- 4.7/203.0 MB 2.9 MB/s eta 0:01:10\n",
      "   - -------------------------------------- 5.5/203.0 MB 2.9 MB/s eta 0:01:08\n",
      "   - -------------------------------------- 6.3/203.0 MB 3.0 MB/s eta 0:01:05\n",
      "   - -------------------------------------- 7.1/203.0 MB 3.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 7.9/203.0 MB 3.1 MB/s eta 0:01:04\n",
      "   - -------------------------------------- 8.4/203.0 MB 3.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 9.2/203.0 MB 3.1 MB/s eta 0:01:03\n",
      "   - -------------------------------------- 10.0/203.0 MB 3.1 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 10.5/203.0 MB 3.1 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 11.3/203.0 MB 3.1 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 12.1/203.0 MB 3.2 MB/s eta 0:01:01\n",
      "   -- ------------------------------------- 12.8/203.0 MB 3.2 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 13.4/203.0 MB 3.2 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 14.2/203.0 MB 3.2 MB/s eta 0:01:00\n",
      "   -- ------------------------------------- 14.9/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 15.7/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 16.3/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 16.8/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 17.6/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 18.4/203.0 MB 3.2 MB/s eta 0:00:59\n",
      "   --- ------------------------------------ 19.1/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   --- ------------------------------------ 19.7/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 20.4/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 21.0/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 21.5/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 22.3/203.0 MB 3.2 MB/s eta 0:00:58\n",
      "   ---- ----------------------------------- 23.1/203.0 MB 3.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 23.9/203.0 MB 3.2 MB/s eta 0:00:57\n",
      "   ---- ----------------------------------- 24.6/203.0 MB 3.2 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 25.4/203.0 MB 3.2 MB/s eta 0:00:56\n",
      "   ----- ---------------------------------- 26.2/203.0 MB 3.2 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 26.7/203.0 MB 3.2 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 27.5/203.0 MB 3.2 MB/s eta 0:00:55\n",
      "   ----- ---------------------------------- 28.3/203.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 29.1/203.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 29.9/203.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 30.7/203.0 MB 3.2 MB/s eta 0:00:54\n",
      "   ------ --------------------------------- 31.5/203.0 MB 3.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 32.0/203.0 MB 3.2 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 32.8/203.0 MB 3.3 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 33.6/203.0 MB 3.2 MB/s eta 0:00:53\n",
      "   ------ --------------------------------- 34.1/203.0 MB 3.2 MB/s eta 0:00:52\n",
      "   ------ --------------------------------- 34.9/203.0 MB 3.3 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 35.7/203.0 MB 3.3 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 36.2/203.0 MB 3.2 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 37.0/203.0 MB 3.3 MB/s eta 0:00:52\n",
      "   ------- -------------------------------- 37.7/203.0 MB 3.3 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 38.5/203.0 MB 3.3 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 39.3/203.0 MB 3.3 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 39.6/203.0 MB 3.3 MB/s eta 0:00:51\n",
      "   ------- -------------------------------- 40.4/203.0 MB 3.2 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 40.9/203.0 MB 3.2 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 41.4/203.0 MB 3.2 MB/s eta 0:00:51\n",
      "   -------- ------------------------------- 42.2/203.0 MB 3.2 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 43.0/203.0 MB 3.2 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 43.5/203.0 MB 3.2 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 44.3/203.0 MB 3.2 MB/s eta 0:00:50\n",
      "   -------- ------------------------------- 45.1/203.0 MB 3.2 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 45.9/203.0 MB 3.2 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 46.7/203.0 MB 3.2 MB/s eta 0:00:49\n",
      "   --------- ------------------------------ 47.4/203.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------- ------------------------------ 48.2/203.0 MB 3.3 MB/s eta 0:00:48\n",
      "   --------- ------------------------------ 49.3/203.0 MB 3.3 MB/s eta 0:00:47\n",
      "   --------- ------------------------------ 50.1/203.0 MB 3.3 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 50.9/203.0 MB 3.3 MB/s eta 0:00:47\n",
      "   ---------- ----------------------------- 51.6/203.0 MB 3.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 52.4/203.0 MB 3.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 53.2/203.0 MB 3.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 54.0/203.0 MB 3.3 MB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 54.8/203.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ---------- ----------------------------- 55.6/203.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 56.4/203.0 MB 3.3 MB/s eta 0:00:45\n",
      "   ----------- ---------------------------- 57.1/203.0 MB 3.3 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 57.9/203.0 MB 3.3 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 58.7/203.0 MB 3.3 MB/s eta 0:00:44\n",
      "   ----------- ---------------------------- 59.5/203.0 MB 3.3 MB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 60.3/203.0 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 61.1/203.0 MB 3.3 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 61.9/203.0 MB 3.4 MB/s eta 0:00:43\n",
      "   ------------ --------------------------- 62.7/203.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 63.4/203.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 64.2/203.0 MB 3.4 MB/s eta 0:00:42\n",
      "   ------------ --------------------------- 65.3/203.0 MB 3.4 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 66.1/203.0 MB 3.4 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 66.8/203.0 MB 3.4 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 67.6/203.0 MB 3.4 MB/s eta 0:00:41\n",
      "   ------------- -------------------------- 68.4/203.0 MB 3.4 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 69.2/203.0 MB 3.4 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 70.0/203.0 MB 3.4 MB/s eta 0:00:40\n",
      "   ------------- -------------------------- 70.8/203.0 MB 3.4 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 71.6/203.0 MB 3.4 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 72.4/203.0 MB 3.4 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 73.4/203.0 MB 3.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 74.2/203.0 MB 3.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 75.0/203.0 MB 3.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 75.8/203.0 MB 3.4 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 76.5/203.0 MB 3.4 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 77.3/203.0 MB 3.4 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 78.1/203.0 MB 3.4 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 78.9/203.0 MB 3.4 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 79.7/203.0 MB 3.4 MB/s eta 0:00:36\n",
      "   --------------- ------------------------ 80.7/203.0 MB 3.4 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 81.5/203.0 MB 3.4 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 82.3/203.0 MB 3.5 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 83.1/203.0 MB 3.5 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 83.9/203.0 MB 3.5 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 84.7/203.0 MB 3.5 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 85.5/203.0 MB 3.5 MB/s eta 0:00:34\n",
      "   ---------------- ----------------------- 86.2/203.0 MB 3.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 87.0/203.0 MB 3.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 87.8/203.0 MB 3.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 88.6/203.0 MB 3.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 89.7/203.0 MB 3.5 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 90.4/203.0 MB 3.5 MB/s eta 0:00:33\n",
      "   ------------------ --------------------- 91.5/203.0 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 92.3/203.0 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 93.3/203.0 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 94.1/203.0 MB 3.5 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 95.2/203.0 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 95.9/203.0 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 97.0/203.0 MB 3.5 MB/s eta 0:00:31\n",
      "   ------------------- -------------------- 98.0/203.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 98.8/203.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 99.9/203.0 MB 3.5 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 100.9/203.0 MB 3.6 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 101.7/203.0 MB 3.6 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 102.8/203.0 MB 3.6 MB/s eta 0:00:29\n",
      "   -------------------- ------------------- 103.8/203.0 MB 3.6 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 104.6/203.0 MB 3.6 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 105.6/203.0 MB 3.6 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 106.4/203.0 MB 3.6 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 107.5/203.0 MB 3.6 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 108.3/203.0 MB 3.6 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 109.3/203.0 MB 3.6 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 110.1/203.0 MB 3.6 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 111.1/203.0 MB 3.7 MB/s eta 0:00:26\n",
      "   ---------------------- ----------------- 111.9/203.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 113.0/203.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 114.0/203.0 MB 3.7 MB/s eta 0:00:25\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "   ---------------------- ----------------- 114.8/203.0 MB 3.7 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 115.6/203.0 MB 3.7 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 116.7/203.0 MB 3.7 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 117.7/203.0 MB 3.7 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 118.5/203.0 MB 3.7 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 119.5/203.0 MB 3.7 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 120.3/203.0 MB 3.7 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 121.4/203.0 MB 3.7 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 122.4/203.0 MB 3.7 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 123.2/203.0 MB 3.7 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 124.3/203.0 MB 3.7 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 125.3/203.0 MB 3.8 MB/s eta 0:00:21\n",
      "   ------------------------ --------------- 126.4/203.0 MB 3.8 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 127.1/203.0 MB 3.8 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 128.2/203.0 MB 3.8 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 129.2/203.0 MB 3.8 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 130.0/203.0 MB 3.8 MB/s eta 0:00:20\n",
      "   ------------------------- -------------- 131.1/203.0 MB 3.8 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 132.1/203.0 MB 3.8 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 132.9/203.0 MB 3.8 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 134.0/203.0 MB 3.8 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 135.0/203.0 MB 3.9 MB/s eta 0:00:18\n",
      "   -------------------------- ------------- 136.1/203.0 MB 3.9 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 137.1/203.0 MB 3.9 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 138.1/203.0 MB 3.9 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 139.2/203.0 MB 3.9 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 140.0/203.0 MB 3.9 MB/s eta 0:00:17\n",
      "   --------------------------- ------------ 141.0/203.0 MB 3.9 MB/s eta 0:00:16\n",
      "   --------------------------- ------------ 142.1/203.0 MB 3.9 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 143.1/203.0 MB 3.9 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 143.9/203.0 MB 3.9 MB/s eta 0:00:16\n",
      "   ---------------------------- ----------- 145.0/203.0 MB 4.0 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 146.0/203.0 MB 4.0 MB/s eta 0:00:15\n",
      "   ---------------------------- ----------- 147.1/203.0 MB 4.0 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 148.1/203.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 149.2/203.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 150.2/203.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 151.0/203.0 MB 4.0 MB/s eta 0:00:14\n",
      "   ----------------------------- ---------- 152.0/203.0 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 153.1/203.0 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 154.1/203.0 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------------------ --------- 155.2/203.0 MB 4.1 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 156.2/203.0 MB 4.1 MB/s eta 0:00:12\n",
      "   ------------------------------ --------- 157.3/203.0 MB 4.1 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 158.3/203.0 MB 4.1 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 159.4/203.0 MB 4.1 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 160.4/203.0 MB 4.1 MB/s eta 0:00:11\n",
      "   ------------------------------- -------- 161.5/203.0 MB 4.1 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 162.5/203.0 MB 4.1 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 163.6/203.0 MB 4.1 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 164.6/203.0 MB 4.2 MB/s eta 0:00:10\n",
      "   -------------------------------- ------- 165.7/203.0 MB 4.2 MB/s eta 0:00:09\n",
      "   -------------------------------- ------- 166.7/203.0 MB 4.2 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 167.8/203.0 MB 4.2 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 168.6/203.0 MB 4.2 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 169.6/203.0 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 170.7/203.0 MB 4.2 MB/s eta 0:00:08\n",
      "   --------------------------------- ------ 171.7/203.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 172.8/203.0 MB 4.2 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 173.5/203.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 174.6/203.0 MB 4.2 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 175.6/203.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ---------------------------------- ----- 176.7/203.0 MB 4.3 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 177.7/203.0 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 178.8/203.0 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 179.8/203.0 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 180.6/203.0 MB 4.3 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 181.7/203.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 182.7/203.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 183.8/203.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 184.8/203.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 185.9/203.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------ --- 186.9/203.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 188.0/203.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 189.0/203.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 190.1/203.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 191.1/203.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 192.2/203.0 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 193.2/203.0 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 194.0/203.0 MB 4.4 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 195.0/203.0 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 196.1/203.0 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 197.1/203.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  198.2/203.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ---------------------------------------  199.2/203.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  200.0/203.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  201.1/203.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.1/203.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  202.9/203.0 MB 4.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 203.0/203.0 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.8/6.2 MB 3.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.6/6.2 MB 4.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.1/6.2 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.6/6.2 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.1/6.2 MB 3.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 3.9/6.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 4.7/6.2 MB 3.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.5/6.2 MB 3.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.2/6.2 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.20.1-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 0.5/1.6 MB 3.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.0/1.6 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.5.1-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.4 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.3/2.4 MB 3.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 2.1/2.4 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 3.3 MB/s eta 0:00:00\n",
      "Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.8/1.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.6/1.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 2.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, networkx, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.5.1 torchaudio-2.5.1 torchvision-0.20.1\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nDistilBertForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFDistilBertForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistilBertForSequenceClassification\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDistilBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m      5\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m      6\u001b[0m )\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1666\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[1;34m(cls, key)\u001b[0m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1665\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[1;32m-> 1666\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1645\u001b[0m, in \u001b[0;36mrequires_backends\u001b[1;34m(obj, backends)\u001b[0m\n\u001b[0;32m   1643\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[0;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[1;32m-> 1645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[0;32m   1647\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[0;32m   1648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[1;31mImportError\u001b[0m: \nDistilBertForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFDistilBertForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the training arguments\n",
    "\n",
    "For lowering the compute time I recommend using the following parameters:\n",
    "- per_device_train_batch_size=128\n",
    "- per_device_eval_batch_size=128\n",
    "- **num_train_epochs=1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"trainer\",\n",
    "    per_device_train_batch_size=128,  \n",
    "    per_device_eval_batch_size=128,   \n",
    "    num_train_epochs=1,               \n",
    "    eval_strategy=\"epoch\",                                                         \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the metrics\n",
    "\n",
    "Load the best metric for the this specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09bdd8d3ffa40a7bf2383fb8c73a175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "import evaluate\n",
    "metric = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to compute the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "def compute_metrics(p):\n",
    "    logits, labels = p\n",
    "    predictions = logits.argmax(axis=-1)  # (0 or 1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Trainer object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code here. Add as many boxes as you need.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m      3\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m----> 4\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m,                         \n\u001b[0;32m      5\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,                  \n\u001b[0;32m      6\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m      7\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mtokenized_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m],  \n\u001b[0;32m      8\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,         \n\u001b[0;32m      9\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics      \n\u001b[0;32m     10\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=tokenized_datasets['train'], \n",
    "    eval_dataset=tokenized_datasets['test'],  \n",
    "    data_collator=data_collator,         \n",
    "    compute_metrics=compute_metrics      \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "\n",
    "Use the trainer to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code here. Add as many boxes as you need.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtrain()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "trainer.train()  #problem so gore model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the predictions (class 0 or 1) from the logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(tokenized_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions, predictions\u001b[38;5;241m.\u001b[39mlabel_ids\n\u001b[0;32m      2\u001b[0m preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(logits, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "logits, labels = predictions.predictions, predictions.label_ids\n",
    "preds = np.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(\u001b[43mlabels\u001b[49m, preds))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Write your code here. Add as many boxes as you need.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(classification_report(tokenized_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mpredicted_labels\u001b[49m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(tokenized_dataset['test']['label'], predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a simple machine learning pipeline to classify if a given text is **toxic** or not. Use TF-IDF vectorization to convert text into numerical features and train a `MultinomialNB` model. If needed use `RandomUnderSampler()`. Compare the results with the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
